from pdf2image import convert_from_path
import pytesseract
import requests

ollama_base_url = "http://localhost:11434"
# ollama_base_url = "http://192.168.10.230:11434"

def text_to_json(text):
    prompt = text + """\n above is bank statement generated by image_to_boxes. You'll have to match the line number to get the transaction details. the columns are trans date,value date, details, debit,credit, balance
e.g. your answer should should be in the format below
{
    "date_from": <date>,
    "date_to": <date>,
    "account_no": <account no>,
    "iban": <iban>,
    "trasactions: [
    {
        "trans_date": "DD/MM/YYYY",
        "value_date": "DD/MM/YYYY",
        "details": "<text>",
        "debit": <amt> | null,
        "credit": amt> | null,
        "balance": <amt>,

    },
    ...
]}"""
    response = requests.post(ollama_base_url + '/api/generate', json={
        "model": "llama3.2",
        "prompt": prompt,
        "stream": False,
        "options": {
            "temperature": 0,
            "seed": 0,
            "num_ctx": 1024 * 8
        }
    })
    return response.json()

def img_to_llm(img):
    json = {
        "model": "llama3.2-vision",
        "stream" : False,
        "messages": [
            {
                "role": "user",
                "content": "give me the statement in JSON format. The amount should be a currency. The desription might be on 2 lines.",
                "images": [img] }
        ],
        "options": {
            "seed": 101,
            "temperature": 0,
            "num_ctx": 1024 * 32
        }
    }
    data = requests.post(ollama_base_url + '/api/chat', json=json)
    print(data.json())

def pdf_to_image(pdf_file_path):
    images = convert_from_path(pdf_file_path,thread_count=8)
    tesseract_config = '-l eng tsv'
    text = ""
    for i, image in enumerate(images):
        import io
        import base64
        byte_array = io.BytesIO()
        image.save(byte_array, format='PNG')
        image_bytes = byte_array.getvalue()
        # print(base64.b64encode(image).decode('utf-8'))
        img_to_llm(base64.b64encode(image_bytes).decode('utf-8'))
        exit(0)
        # print(pytesseract.image_to_data(image))
        text += str(pytesseract.image_to_string(image))
    print(text)
    # exit(0)
    response = text_to_json(text)
    # print(response)
    print(response['response'])
    print(response['total_duration']/1000000000)

# Example usage:
pdf_to_image("../data/bankstatements/Current_Savings_account_statement_000450113027_20240628.pdf")
img_to_llm()